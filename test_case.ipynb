{"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"yYZWKMvRBV8I"},"id":"yYZWKMvRBV8I"},{"cell_type":"code","source":["pwd"],"metadata":{"id":"ZHx7KE-WClGd","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1716137841188,"user_tz":-480,"elapsed":527,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"a7a66b89-7deb-4ead-c28a-cb140e238be4"},"id":"ZHx7KE-WClGd","execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNLjaapyBXhj","executionInfo":{"status":"ok","timestamp":1716137865781,"user_tz":-480,"elapsed":24059,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"f8f8aa52-47d2-4b19-f9d0-bd77c16657ad"},"id":"gNLjaapyBXhj","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/FIT3162')"],"metadata":{"id":"0iGZ1wdMzq3H","executionInfo":{"status":"ok","timestamp":1716137865781,"user_tz":-480,"elapsed":4,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}}},"id":"0iGZ1wdMzq3H","execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pyts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZ5uZwOK3FT6","executionInfo":{"status":"ok","timestamp":1716137874425,"user_tz":-480,"elapsed":8647,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"0cdb83cd-55a1-4a49-eff4-68af49b5c279"},"id":"pZ5uZwOK3FT6","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyts\n","  Downloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.25.2)\n","Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.11.4)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from pyts) (1.4.2)\n","Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts) (0.58.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts) (0.41.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->pyts) (3.5.0)\n","Installing collected packages: pyts\n","Successfully installed pyts-0.13.0\n"]}]},{"cell_type":"code","source":["import unittest\n","\n","import numpy as np\n","import unittest\n","import numpy as np\n","import LSTM_train_eva\n"],"metadata":{"id":"JqjUk8pj26-O","executionInfo":{"status":"ok","timestamp":1716137893885,"user_tz":-480,"elapsed":19473,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}}},"id":"JqjUk8pj26-O","execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","import unittest\n","\n","class TestModelTraining(unittest.TestCase):\n","\n","  def setUp(self):\n","      # Initialize a Data_util object with mock data and parameters\n","      self.data = LSTM_train_eva.Data_util('data/electricity.txt', 0.6, 0.2, False, 12, 24 * 7, 2)\n","      self.X_train, self.Y_train = self.data.train[0], self.data.train[1]# Get training data batches\n","\n","      # Initialize a simple LSTM model\n","      self.model = LSTM_train_eva.LSTM(input_size=len(self.X_train[0][0]), hidden_size=128)\n","\n","      # Initialize a loss function and optimizer\n","      self.criterion = torch.nn.MSELoss()\n","      self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n","\n","      # Move model to GPU if available\n","      self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","      self.model.to(self.device)\n","      self.X_train = self.X_train.to(self.device)\n","      self.Y_train = self.Y_train.to(self.device)\n","\n","  def test_model_weights_update(self):\n","    def train(model, data, X, Y, criterion, optimizer, batch_size):\n","      model.train()  # Set the model to training mode\n","      total_loss = 0\n","      n_samples = 0\n","      count = 0\n","\n","      for X_batch, Y_batch in data.get_batches(X, Y, batch_size, True):\n","        #run once only\n","        if count < 3:\n","          optimizer.zero_grad()  # Clear gradients\n","          hidden_state, output = model(128,X_batch)  # Forward pass\n","          loss = criterion(output, Y_batch)  # Compute loss\n","          loss.backward()  # Backward pass\n","          optimizer.step()  # Update weights\n","\n","          total_loss += loss.item()\n","          n_samples += X_batch.size(0)  # Increment sample count\n","          count += 1\n","      return total_loss / n_samples\n","\n","    # Before training, save the initial weights\n","    initial_weights = [param.data.clone() for param in self.model.parameters()]\n","\n","    # Perform one training step\n","    train(self.model, self.data, self.X_train, self.Y_train, self.criterion, self.optimizer, batch_size=128)\n","\n","    # After training, check if the weights have changed\n","    updated_weights = [param.data.clone() for param in self.model.parameters()]\n","\n","    # Check if all corresponding weights in the lists are equal\n","    weights_equal = all(torch.equal(iw, uw) for iw, uw in zip(initial_weights, updated_weights))\n","\n","    self.assertFalse(weights_equal, \"Weights should be updated during training\")\n","\n","if __name__ == '__main__':\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BxpA-obphoWv","executionInfo":{"status":"ok","timestamp":1716137258305,"user_tz":-480,"elapsed":8158,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"26927e4d-8f9c-4b7e-d2ea-579b440da7d1"},"id":"BxpA-obphoWv","execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n",".\n","----------------------------------------------------------------------\n","Ran 1 test in 7.956s\n","\n","OK\n"]}]},{"cell_type":"code","source":["import torch\n","import unittest\n","from LSTM_train_eva import LSTM, LSTMCell, InputGate, ForgetGate, OutputGate # Ensure this import matches the training script\n","\n","class TestModelLoadingAndPrediction(unittest.TestCase):\n","    def setUp(self):\n","        # Path to the saved model parameters\n","        self.model_path = 'model/model.pt'\n","\n","        # Replace these with the actual input and hidden sizes of your model\n","        self.input_size = 10\n","        self.hidden_size = 128\n","\n","        # Batch size for the dummy input; typically 1 for a single sequence\n","        self.batch_size = 1\n","\n","        # Sequence length is assumed to be 1 for simplicity in this test\n","        self.sequence_length = 128\n","\n","        # Create a dummy input tensor with the appropriate size\n","        # (batch_size, sequence_length, input_size)\n","        self.dummy_input = torch.randn(self.batch_size, self.sequence_length, self.input_size)\n","\n","        # Load the model\n","        # Ensure the LSTM class here is the same as the one used during training\n","        # self.model = LSTM_train_eva.LSTM(input_size=self.input_size, hidden_size=self.hidden_size)\n","        self.model = torch.load(self.model_path)\n","        self.model.eval()  # Set the model to evaluation mode\n","\n","    def test_model_prediction(self):\n","        \"\"\"\n","        Test if the loaded model can make predictions on dummy input.\n","        \"\"\"\n","        with torch.no_grad():\n","            # Perform a forward pass through the model to get predictions\n","            # If your model returns only the final output, you might not need the _ (underscore)\n","            _, predictions = self.model(128,self.dummy_input)\n","\n","            # Check if the model produced any output\n","            self.assertIsNotNone(predictions, \"The model should produce predictions\")\n","\n","            # Check if the predictions have the correct shape\n","            # The expected shape might vary depending on your model's output\n","            # Here we expect (batch_size, sequence_length, hidden_size)\n","            expected_shape = (self.dummy_input.size(0), self.dummy_input.size(1), self.hidden_size)\n","            self.assertEqual(predictions.shape, expected_shape, \"Predictions should have the expected shape\")\n","\n","if __name__ == '__main__':\n","    # The 'first-arg-is-ignored' is a workaround for unittest when running in some IDEs\n","    # that may pass the script name as an argument.\n","    unittest.main(argv=['first-arg-is-ignored'], exit=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vULgohd1riqd","executionInfo":{"status":"ok","timestamp":1716138118815,"user_tz":-480,"elapsed":679,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"d1195bd6-eba4-40b5-b58b-ac0fe981c777"},"id":"vULgohd1riqd","execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","E\n","======================================================================\n","ERROR: test_model_prediction (__main__.TestModelLoadingAndPrediction)\n","Test if the loaded model can make predictions on dummy input.\n","----------------------------------------------------------------------\n","Traceback (most recent call last):\n","  File \"<ipython-input-13-4e2b55184f1c>\", line 37, in test_model_prediction\n","    _, predictions = self.model(128,self.dummy_input)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 431, in forward\n","    h_t, c_t = self.lstm_cell(x_t, h_t, c_t)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 397, in forward\n","    i_t, c_mu = self.input_gate.forward(x_t, h_prev)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 365, in forward\n","    i_t = super().forward(x_t, h_prev)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 324, in forward\n","    z = torch.matmul(concat,self.W) + self.b\n","RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x129 and 256x128)\n","\n","----------------------------------------------------------------------\n","Ran 1 test in 0.039s\n","\n","FAILED (errors=1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoSNKw3w95Nl","executionInfo":{"status":"ok","timestamp":1716097895076,"user_tz":-480,"elapsed":34073,"user":{"displayName":"Dizhen Liang","userId":"06557023756950998584"}},"outputId":"8e9e2879-29de-4dd5-9098-6afbddbcf66f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","EEE\n","======================================================================\n","ERROR: test_arm (__main__.TestData)\n","----------------------------------------------------------------------\n","Traceback (most recent call last):\n","  File \"<ipython-input-6-6614ca2330cd>\", line 8, in setUp\n","    self.data2 = LSTM_train_eva.Data_util('data/solar_AL.txt', 0.7, 0.2, False, 12, 24 * 7, 0)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 45, in __init__\n","    self._arm(5, 0.7, 0.7, 50)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 80, in _arm\n","    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=min_threshold)\n","  File \"/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/association_rules.py\", line 83, in association_rules\n","    raise ValueError(\n","ValueError: The input DataFrame `df` containing the frequent itemsets is empty.\n","\n","======================================================================\n","ERROR: test_data_object_creation (__main__.TestData)\n","----------------------------------------------------------------------\n","Traceback (most recent call last):\n","  File \"<ipython-input-6-6614ca2330cd>\", line 8, in setUp\n","    self.data2 = LSTM_train_eva.Data_util('data/solar_AL.txt', 0.7, 0.2, False, 12, 24 * 7, 0)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 45, in __init__\n","    self._arm(5, 0.7, 0.7, 50)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 80, in _arm\n","    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=min_threshold)\n","  File \"/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/association_rules.py\", line 83, in association_rules\n","    raise ValueError(\n","ValueError: The input DataFrame `df` containing the frequent itemsets is empty.\n","\n","======================================================================\n","ERROR: test_split (__main__.TestData)\n","----------------------------------------------------------------------\n","Traceback (most recent call last):\n","  File \"<ipython-input-6-6614ca2330cd>\", line 8, in setUp\n","    self.data2 = LSTM_train_eva.Data_util('data/solar_AL.txt', 0.7, 0.2, False, 12, 24 * 7, 0)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 45, in __init__\n","    self._arm(5, 0.7, 0.7, 50)\n","  File \"/content/drive/MyDrive/FIT3162/LSTM_train_eva.py\", line 80, in _arm\n","    rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=min_threshold)\n","  File \"/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/association_rules.py\", line 83, in association_rules\n","    raise ValueError(\n","ValueError: The input DataFrame `df` containing the frequent itemsets is empty.\n","\n","----------------------------------------------------------------------\n","Ran 3 tests in 33.829s\n","\n","FAILED (errors=3)\n"]}],"source":["\n","# class TestData(unittest.TestCase):\n","#     def setUp(self):\n","#         self.data1 = LSTM_train_eva.Data_util('data/electricity.txt', 0.6, 0.2, False, 12, 24 * 7, 2)\n","#         self.data2 = LSTM_train_eva.Data_util('data/solar_AL.txt', 0.7, 0.2, False, 12, 24 * 7, 0)\n","\n","#     def test_data_object_creation(self):\n","#         print(\"Test data object creation\")\n","#         self.assertIsInstance(self.data1, LSTM_train_eva.Data_util)\n","#         self.assertIsInstance(self.data2, LSTM_train_eva.Data_util)\n","\n","#     def test_arm(self):\n","#         print(\"Test arm\")\n","#         with open('data/electricity.txt') as file1, open('data/solar_AL.txt') as file2:\n","#             no_rows1 = len(np.loadtxt(file1, delimiter=',')[0])\n","#             no_rows2 = len(np.loadtxt(file2, delimiter=',')[0])\n","\n","#         self.assertLess(len(self.data1.rawdat[0]), no_rows1)\n","#         self.assertEqual(len(self.data2.rawdat[0]), no_rows2)\n","\n","#     def test_split(self):\n","#         print(\"Test split\")\n","#         with open('data/electricity.txt') as file1, open('data/solar_AL.txt') as file2:\n","#             data1 = np.loadtxt(file1, delimiter=',')\n","#             data2 = np.loadtxt(file2, delimiter=',')\n","\n","#         # Assuming Data_util class splits the data correctly, adjust the calculations if needed\n","#         no_train_cols1 = int(len(data1) * 0.6) + 1 - 24 * 7 - 12\n","#         no_val_cols1 = int(len(data1) * 0.2) + 1\n","#         no_test_cols1 = int(len(data1) * 0.2) + 1\n","\n","#         no_train_cols2 = int(len(data2) * 0.7) + 1 - 24 * 7 - 12\n","#         no_val_cols2 = int(len(data2) * 0.2) - 1\n","#         no_test_cols2 = int(len(data2) * 0.1) + 1\n","\n","#         self.assertEqual(len(self.data1.train[0]), no_train_cols1)\n","#         self.assertEqual(len(self.data1.valid[0]), no_val_cols1)\n","#         self.assertEqual(len(self.data1.test[0]), no_test_cols1)\n","\n","#         self.assertEqual(len(self.data2.train[0]), no_train_cols2)\n","#         self.assertEqual(len(self.data2.valid[0]), no_val_cols2)\n","#         self.assertEqual(len(self.data2.test[0]), no_test_cols2)\n","\n","# if __name__ == '__main__':\n","#     unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"],"id":"JoSNKw3w95Nl"}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}